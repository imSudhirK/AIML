{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hRpsy5Zp8Lr"
      },
      "source": [
        "\n",
        "## <font color=red> You should not import any new libraries. Your code should run with python=3.x</font>\n",
        "## <font color=red> Please don't rename this .ipynb file.</font><br>\n",
        "- Your solutions will be auto-graded. Hence we request you to follow the instructions.\n",
        "- Modify the code only between \n",
        "```\n",
        "## TODO\n",
        "## END TODO\n",
        "```\n",
        "- In addition to above changes, you can play with arguments to the functions for generating plots\n",
        "- We will run the auto grading scripts with private test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBBZWQn3WjsN"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxgQgosmYXRu"
      },
      "source": [
        "##LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSk_qe4RXFYz"
      },
      "source": [
        "X = np.load('./data/train_X.npy')\n",
        "Y = np.array([np.load('./data/train_y.npy')]).T"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR4FU-VdluE-"
      },
      "source": [
        "# print(X.shape)\n",
        "# print(Y.shape)\n",
        "# print(X[1, :])\n",
        "# print(X)\n",
        "# print(Y[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9j3in3odIle"
      },
      "source": [
        "Normalization / Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaYuScGvdEum"
      },
      "source": [
        "def normalize(X):\n",
        "  \"\"\"\n",
        "  Implement Normalization for input image features\n",
        "\n",
        "  Args:\n",
        "  X : numpy array of shape (n_samples, 784)\n",
        "   \n",
        "  Returns:\n",
        "  X_norm : numpy array of shape (n_samples, 784) after normalization\n",
        "  \"\"\"\n",
        "  X_norm = None\n",
        "  \n",
        "  ## TODO\n",
        "  x_mean = np.mean(X, axis=0)\n",
        "  x_std  = np.std(X, axis=0)\n",
        "  X_norm = (X - x_mean)/ (x_std + 0.00001)\n",
        "  \n",
        "  ## END TODO\n",
        "\n",
        "  assert X_norm.shape == X.shape\n",
        "\n",
        "  return X_norm\n",
        "\n",
        "def scaling(X):\n",
        "  \"\"\"\n",
        "  Implement MinMax Scaling on input image features\n",
        "\n",
        "  Args:\n",
        "  X : numpy array of shape (n_samples, 784)\n",
        "   \n",
        "  Returns:\n",
        "  X_scaled : numpy array of shape (n_samples, 784)\n",
        "  \"\"\"\n",
        "  X_scaled = None\n",
        "\n",
        "  ##TODO\n",
        "  x_min = np.min(X, axis=0)\n",
        "  x_max = np.max(X, axis=0)\n",
        "  X_scaled = (X - x_min) / (x_max - x_min + 0.00001)\n",
        "  \n",
        "  ##END TODO\n",
        "  \n",
        "  assert X_scaled.shape == X.shape\n",
        "\n",
        "  return X_scaled"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeUNEDHtQiLc"
      },
      "source": [
        "# print(normalize(X)[:5, :10])\n",
        "# print(scaling(X)[:5, :10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejROq-52YUol"
      },
      "source": [
        "### Split data into train/val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l07sJgZ3XG-N"
      },
      "source": [
        "def split_data(X, Y, train_ratio=0.8):\n",
        "    '''\n",
        "    Split data into train and validation sets\n",
        "    The first floor(train_ratio*n_sample) samples form the train set\n",
        "    and the remaining the test set\n",
        "\n",
        "    Args:\n",
        "    X - numpy array of shape (n_samples, n_features)\n",
        "    Y - numpy array of shape (n_samples, 1)\n",
        "    train_ratio - fraction of samples to be used as training data\n",
        "\n",
        "    Returns:\n",
        "    X_train, Y_train, X_val, Y_val\n",
        "    '''\n",
        "    # Try Normalization and scaling and store it in X_transformed\n",
        "    X_transformed = X\n",
        "\n",
        "    ## TODO\n",
        "\n",
        "    X_transformed = normalize(X)\n",
        "    # X_transformed = scaling(X)\n",
        "\n",
        "    n_samples = X_transformed.shape[0]\n",
        "    S = np.arange(n_samples)\n",
        "    np.random.shuffle(S)\n",
        "    X_ = X_transformed[S]\n",
        "    Y_ = Y[S]\n",
        "\n",
        "    dim = X_.ndim\n",
        "    if dim  ==1:\n",
        "      X_ = X_.reshape(-1, 1)\n",
        "\n",
        "    train_size = int(np.floor(n_samples*train_ratio))\n",
        "    X_train = X_[:train_size,:]\n",
        "    Y_train = Y_[:train_size]\n",
        "    X_val = X_[train_size:,:]\n",
        "    Y_val = Y_[train_size:]\n",
        "    \n",
        "    ## END TODO\n",
        "\n",
        "    assert X_transformed.shape == X.shape\n",
        "\n",
        "    num_samples = len(X)\n",
        "    indices = np.arange(num_samples)\n",
        "    num_train_samples = math.floor(num_samples * train_ratio)\n",
        "    train_indices = np.random.choice(indices, num_train_samples, replace=False)\n",
        "    val_indices = list(set(indices) - set(train_indices))\n",
        "    X_train, Y_train, X_val, Y_val = X_transformed[train_indices], Y[train_indices], X_transformed[val_indices], Y[val_indices]\n",
        "  \n",
        "    return X_train, Y_train, X_val, Y_val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT-b4s1Kb6eL"
      },
      "source": [
        "**Plotting image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jlAZLOtY73s"
      },
      "source": [
        "def plot_image(x, y, idx):\n",
        "  \"\"\"\n",
        "  Plot the given feature vector into image of size 28 X 28 \n",
        "  note that originally the image was of size 28*28 which is flattened or unrolled\n",
        "  to 784 X 1 feature vector\n",
        "\n",
        "  Args:\n",
        "  x : numpy array of images\n",
        "  y : numpy array of ground truth labels for images\n",
        "  idx : index of the image\n",
        "  \"\"\"\n",
        "\n",
        "  image = np.reshape(x[idx], (28,28))\n",
        "  plt.imshow(image, interpolation='nearest')\n",
        "  plt.show()\n",
        "  print (f'The ground truth label for this iamge is : {y[idx]}')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkI57T5zdsci"
      },
      "source": [
        "Encode 1 for any one of the class and 0 to all other remaining class for all labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlRACMv1WggK"
      },
      "source": [
        "def get_data_for_class(X,Y,id):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "  X : numpy array of input features, shape - (n_samples x 784)\n",
        "  Y : numpy array of input targets, shape - (n_samples x 1)\n",
        "  id : class id (one of 1,4,7,9)\n",
        "\n",
        "  Returns:\n",
        "  class_X : numpy array of input features, shape - (n_samples x 784)\n",
        "  class_Y : numpy array of input targets, where class_Y[i]=1 if Y[i]=id else class_Y[i]=0, shape - (n_samples x 784)\n",
        "  \"\"\"\n",
        "  class_X, class_Y = None, None\n",
        "\n",
        "  ##TODO\n",
        "  class_X = X\n",
        "  class_Y = Y == id\n",
        "  ##END TODO\n",
        "\n",
        "  assert class_X.shape == X.shape and class_Y.shape == Y.shape\n",
        "\n",
        "  return class_X, class_Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFhZGe-2djbu"
      },
      "source": [
        "Random Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKCNwUdgdi91"
      },
      "source": [
        "def sample_training_points(X, y, sample_size):\n",
        "  \"\"\"\n",
        "  Takes input features, targets and sample size, and returns random sample of size = sample_size\n",
        "\n",
        "  Args: \n",
        "  X : numpy array of shape (n_samples , n_features)\n",
        "  y : numpy array of shape (n_samples , 1)\n",
        "  \n",
        "  Returns: \n",
        "  sampled_X : numpy array of shape (sample_size , n_eatures)\n",
        "  sampled_y : numpy array of shape (sample_size , 1)\n",
        "\n",
        "  \"\"\"\n",
        "  sampled_X , sampled_y = None, None\n",
        "  \n",
        "  ##TODO\n",
        "  n_samples = X.shape[0]\n",
        "  S = np.arange(n_samples)\n",
        "  np.random.shuffle(S)\n",
        "  X_random = X[S]\n",
        "  Y_random = y[S]\n",
        "\n",
        "  sampled_X = X_random[:sample_size,:]\n",
        "  sampled_y = Y_random[:sample_size]\n",
        " \n",
        "  ##END TODO\n",
        "\n",
        "  assert sampled_X.shape==(sample_size,X.shape[1]) and sampled_y.shape==(sample_size,1)\n",
        "  \n",
        "  return sampled_X, sampled_y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE4aGEKSf_mo"
      },
      "source": [
        "LOGISTIC REGRESSION CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmQHu4nYgksD"
      },
      "source": [
        "def sigmoid(weights, bias, X):\n",
        "  \"\"\"\n",
        "  Implement logistic/ sigmoid function\n",
        "\n",
        "  Args:\n",
        "  weights : numpy array of shape (n_dimension , 1)\n",
        "  bias : scaler\n",
        "  X : numpy array of shape (n_samples , n_dimension)\n",
        "\n",
        "  Returns: \n",
        "  Y_sigmoid : numpy array of shape (n_samples, 1)\n",
        "  \"\"\"\n",
        "  Y_sigmoid = None\n",
        "\n",
        "  ##TODO\n",
        "\n",
        "  y =  X @ weights + bias  \n",
        "  Y_sigmoid = 1.0 / (1.0 + np.exp(-y))\n",
        "  \n",
        "  ##END TODO\n",
        "  assert Y_sigmoid.shape == (X.shape[0],1)\n",
        "\n",
        "  return Y_sigmoid\n",
        "\n",
        "\n",
        "def cross_entropy_loss(weights, bias, X, y):\n",
        "  \"\"\"\n",
        "  Takes input features, weights, bias and target \n",
        "  and calculates binary cross entropy loss between y and predicted values of y.\n",
        "\n",
        "  Args:\n",
        "  weights : numpy array of shape (n_features, 1)\n",
        "  bias : scalar\n",
        "  X : numpy array of shape (n_samples, 1)\n",
        "  y : numpy array of shape (n_samples, 1)\n",
        "  \n",
        "  Returns :\n",
        "  loss : single float value\n",
        "  \"\"\"\n",
        "  loss = 0.0\n",
        "\n",
        "  ##TODO\n",
        "  n_samples = X.shape[0]\n",
        "  p_Y_hat = sigmoid(weights, bias, X)\n",
        "  entropy = (y.T @ np.log(p_Y_hat + 0.000001))\n",
        "  loss = entropy + (1- y.T) @ np.log( 1 - p_Y_hat + 0.000001)\n",
        "  loss = - loss[0][0] /(1.0*n_samples)\n",
        "  \n",
        "  ##END TODO\n",
        "\n",
        "  return loss\n",
        "\n",
        "def grad(X, y, weights, bias):\n",
        "\n",
        "  \"\"\"\n",
        "  Return gradient for weights and biases\n",
        "\n",
        "  Args:\n",
        "  X : numpy array of shape (n_samples , n_dimension)\n",
        "  y : numpy array of shape (n_samples , 1)\n",
        "  weights : numpy array of shape (n_dimension , 1)\n",
        "  bias : scalar\n",
        "\n",
        "  Returns: \n",
        "  gradient : [dw , db]\n",
        "              dw - numpy array of shape (n_dimension , 1)\n",
        "              db - numpy array of shape (1)\n",
        "  \"\"\"\n",
        "\n",
        "  dw , db = None , None\n",
        "\n",
        "  ##TODO\n",
        "  n_samples = X.shape[0]\n",
        "  Y_hat = sigmoid(weights, bias, X)\n",
        "  delta_w = X.T @ (Y_hat - y)\n",
        "  dw = delta_w /(1.0* n_samples)\n",
        "\n",
        "  ones_mat = np.ones(X.shape[0], float).reshape(-1, 1)\n",
        "  delta_b = Y_hat - y\n",
        "  # print(delta_b.T.shape, ones_mat.shape)\n",
        "  delta_b = delta_b.T @ ones_mat\n",
        "  db = delta_b[0][0] /(1.0*n_samples)\n",
        "  \n",
        "  ##END TODO\n",
        "\n",
        "  assert dw.shape == weights.shape \n",
        "  assert isinstance(db, float)\n",
        "\n",
        "  gradient = [dw , db]\n",
        "\n",
        "  return gradient\n",
        "\n",
        "def logistic_regression(X, y, epoch, lr, sample_size):\n",
        "  \"\"\"\n",
        "  Args :\n",
        "\n",
        "  X : numpy array of inpuy features of shape (n_samples, n_features)\n",
        "  y : numpy array of targets of shape (n_samples, 1)\n",
        "  epochs : number of iterations of training\n",
        "  lr : learning_rate\n",
        "  sample_size : batch_size for each iteration\n",
        "\n",
        "  Returns : \n",
        "  loss : list containg loss for each epoch\n",
        "  weights : numpy array of shape (n_features, 1)\n",
        "  bias :  scaler\n",
        "  \"\"\"\n",
        "\n",
        "  loss, weights, bias = [], None, 0\n",
        "  #define weights and bias (w, b) initialize the weight\n",
        "\n",
        "  ##TODO\n",
        "  weights = np.zeros(784, float).reshape(-1, 1)\n",
        "\n",
        "  for i in range(0, epoch):\n",
        "    X_sample, Y_sample = sample_training_points(X, y, sample_size)\n",
        "    # print(\"X_sample\", X_sample)\n",
        "    # print(\"Y_sample\", Y_sample)\n",
        "\n",
        "    gradient  = grad(X_sample, Y_sample, weights, bias)\n",
        "    d_w, d_b = gradient[0], gradient[1]\n",
        "\n",
        "    # print(\"gradient\", d_w[:5, :], d_b)\n",
        "\n",
        "    weights = weights - lr*d_w\n",
        "    bias = bias - lr*d_b\n",
        "    loss_sample = cross_entropy_loss(weights, bias, X, y)\n",
        "    # print(\"loss\", loss_sample)\n",
        "    # print(\"weights\", weights[:5,:])\n",
        "    # print(\"bias\", bias)\n",
        "\n",
        "    loss.append(loss_sample)\n",
        "\n",
        "  ##TODO\n",
        "  assert len(loss) == epoch and weights.shape == (X.shape[1],1)\n",
        "\n",
        "  return [loss, weights, bias]\n",
        "\n",
        "def train_multi_class(X, Y):\n",
        "  \"\"\"\n",
        "  make multi class classifier using binary classification (1 vs all)\n",
        "\n",
        "  Args:\n",
        "  X : numpy array of input features of shape (n_samples, n_features)\n",
        "  Y : numpy array of input features of shape (n_samples, 1)\n",
        "\n",
        "  Returns:\n",
        "\n",
        "  param_list : list of param for all classifiers, where param = [weights, bias]\n",
        "  loss_list : list of lists of losses of all classifiers for all epochs\n",
        "  \"\"\"\n",
        "\n",
        "  digits = [1,4,7,9]\n",
        "  param_list = []\n",
        "  loss_list = []\n",
        "\n",
        "\n",
        "  #train i vs all weights and bias, where i in {1,4,7,9}\n",
        "  epochs , lr , sample_size = 500, 0.01, 120\n",
        "  # epochs , lr , sample_size = 5, 0.01, 10\n",
        "\n",
        "  for i in digits:\n",
        "    X_train, Y_train = get_data_for_class(X, Y, id=i)\n",
        "    # print(Y_train)\n",
        "    output = logistic_regression(X_train, Y_train, epochs, lr, sample_size)\n",
        "    param_list.append(output[1:]) \n",
        "    loss_list.append(output[0])   \n",
        "\n",
        "  return param_list, loss_list"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY8FbTF9KfzR"
      },
      "source": [
        "# print(loss_list)\n",
        "# print(len(param_lists))\n",
        "# print(len(param_lists[0]))\n",
        "# print(param_lists[0][0].shape)\n",
        "# print(param_lists[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w96QeoELvelA"
      },
      "source": [
        "def to_class(predicts):\n",
        "  \"\"\"\n",
        "  Args: \n",
        "  predicts : numpy array of shape (n_samples, 4)\n",
        "  \n",
        "  Return:\n",
        "  predicted classes : numpy array of shape(num_samples, class_id), where class_id in {1,4,7,9}\n",
        "  \n",
        "  \"\"\"\n",
        "  labels = {0:1, 1:4, 2:7, 3:9}\n",
        "  predicted_class = []\n",
        "  for i in range(predicts.shape[0]):\n",
        "    label = np.argmax(predicts[i])\n",
        "    predicted_class.append(labels[label])\n",
        "\n",
        "  return np.array(predicted_class).reshape(len(predicted_class),1)\n",
        "\n",
        "def prediction(param, X):\n",
        "  \"\"\"\n",
        "  It return the array of predicted class for all samples in X                                    \n",
        "\n",
        "  Args: \n",
        "  param[0] = [w,b] of class 1 vs all\n",
        "  param[1] = [w,b] of class 4 vs all\n",
        "  param[2] = [w,b] of class 7 vs all\n",
        "  param[3] = [w,b] of class 9 vs all\n",
        "\n",
        "  X = numpy array of input features, shape (n_samples , 784)\n",
        "\n",
        "  Returns:\n",
        "  predicts = numpy array for shape (n_samples , 4), \n",
        "             where predicts[i][j] is probablity that sample i belongs to class j when using classifer j vs all\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  predicts = None\n",
        "\n",
        "  ##TODO\n",
        "  ones_mat = np.ones(X.shape[0], float)\n",
        "  X_ones  = np.append(X, ones_mat.reshape(-1, 1), axis = 1)\n",
        "\n",
        "  param_mat = np.array(param)\n",
        "  pw = param_mat[0][0].reshape(1, 784)\n",
        "  pw1 = param_mat[1][0].reshape(1, 784)\n",
        "  pw2 = param_mat[2][0].reshape(1, 784)\n",
        "  pw3 = param_mat[3][0].reshape(1, 784)\n",
        "  pb = param_mat[:, 1].reshape(4,1)\n",
        "\n",
        "  final_w = np.concatenate((pw, pw1, pw2, pw3), axis=0)\n",
        "  final_param = np.concatenate((final_w, pb), axis=1)\n",
        "  # print(final_param.shape)\n",
        "  # print(pb)\n",
        "\n",
        "  predicts = X_ones @ final_param.T\n",
        "  \n",
        "  ##END TODO\n",
        "  assert predicts.shape == (X.shape[0],4)\n",
        "\n",
        "  return predicts\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2om8E02u579X"
      },
      "source": [
        "def accuracy(Y_pred, Y_true):\n",
        "\n",
        "  '''\n",
        "  This functions calculates accuracy for -\n",
        "    1) each of the 4 class \n",
        "    2) whole dataset\n",
        "    Note : Do not report in percentage\n",
        "\n",
        "  Args:\n",
        "  Y_pred : Predicted class labels, numpy array of shape (n_samples , 1)\n",
        "  Y_true : True/Actual class labels, numpy array of shape (n_samples , 1)\n",
        "\n",
        "  Returns:\n",
        "  list of length 5, 1 st value is overall accuracy followed by accuracy of all 4 individual classifies\n",
        "  '''\n",
        "  \n",
        "  total_accuracy = np.sum(Y_pred==Y_true)/Y_true.shape[0]\n",
        "  accuracy_1 , accuracy_4 , accuracy_7 , accuracy_9 = 0, 0, 0, 0\n",
        "  #TODO\n",
        "  tot_count = [0, 0, 0, 0]\n",
        "  correct_count = [0, 0, 0, 0]\n",
        "  for i in range(len(Y_true)):\n",
        "    if Y_true[i] == 1:\n",
        "      tot_count[0] += 1\n",
        "      if Y_pred[i] == 1:\n",
        "        correct_count[0] += 1\n",
        "    elif Y_true[i] == 4:\n",
        "      tot_count[1] += 1\n",
        "      if Y_pred[i] == 4:\n",
        "        correct_count[1] += 1\n",
        "    elif Y_true[i] == 7:\n",
        "      tot_count[2] += 1\n",
        "      if Y_pred[i] == 7:\n",
        "        correct_count[2] += 1\n",
        "    elif Y_true[i] == 9:\n",
        "      tot_count[3] += 1\n",
        "      if Y_pred[i] == 9:\n",
        "        correct_count[3] += 1\n",
        "  accuracy_1 = 1.0*correct_count[0] / (1.0*tot_count[0])\n",
        "  accuracy_4 = 1.0*correct_count[1] / (1.0*tot_count[1])\n",
        "  accuracy_7 = 1.0*correct_count[2] / (1.0*tot_count[2])\n",
        "  accuracy_9 = 1.0*correct_count[3] / (1.0*tot_count[3])\n",
        "\n",
        "  ##END TO\n",
        "\n",
        "  print(\"Total Accuray : \", total_accuracy) \n",
        "  print(\"Accuray class 1 : \", accuracy_1) \n",
        "  print(\"Accuray class 4 : \", accuracy_4) \n",
        "  print(\"Accuray class 7 : \", accuracy_7) \n",
        "  print(\"Accuray class 9 : \", accuracy_9) \n",
        "\n",
        "  return [total_accuracy, accuracy_1, accuracy_4, accuracy_7, accuracy_9]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9_jRs0bsU5"
      },
      "source": [
        "def calculate_metrics(Y_pred, Y_true):\n",
        "\n",
        "  '''\n",
        "  This functions calculates precision, recall and f1-score for -\n",
        "    1) each of the 4 class \n",
        "    2) whole dataset\n",
        "    Note : Do not report in percentage\n",
        "\n",
        "  Args:\n",
        "  Y_pred : Predicted class labels, numpy array of shape (n_samples , 1)\n",
        "  Y_true : True/Actual class labels, numpy array of shape (n_samples , 1)\n",
        "\n",
        "  Returns:\n",
        "  (precision , recall , f1_score) : a tuple of 3 lists i.e. precison, recall and f1_score where\n",
        "          precision : list of length 5, 1 st value is overall precison followed by precision of all 4 individual classes\n",
        "          recall : list of length 5, 1 st value is overall recall followed by recall of all 4 individual classes\n",
        "          f1_score : list of length 5, 1 st value is overall f1-score followed by f1-score of all 4 individual classes\n",
        "  '''\n",
        "\n",
        "  precision , recall , f1_score = [], [] ,[]\n",
        "\n",
        "  ## TODO\n",
        "  precision , recall , f1_score = [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]\n",
        "  TP = [0, 0, 0, 0]\n",
        "  FP = [0, 0, 0, 0]\n",
        "  FN = [0, 0, 0, 0]\n",
        "  for i in range(len(Y_true)):\n",
        "    if Y_pred[i] == 1 and Y_true[i] == 1:\n",
        "      TP[0] +=1\n",
        "    elif Y_pred[i] == 4 and Y_true[i] == 4:\n",
        "      TP[1] +=1\n",
        "    elif Y_pred[i] == 7 and Y_true[i] == 7:\n",
        "      TP[2] +=1\n",
        "    elif Y_pred[i] == 9 and Y_true[i] == 9:\n",
        "      TP[3] +=1\n",
        "    elif Y_pred[i] == 1 and Y_true[i] != 1:\n",
        "      FP[0] +=1\n",
        "    elif Y_pred[i] == 4 and Y_true[i] != 4:\n",
        "      FP[1] +=1\n",
        "    elif Y_pred[i] == 7 and Y_true[i] != 7:\n",
        "      FP[2] +=1\n",
        "    elif Y_pred[i] == 9 and Y_true[i] != 9:\n",
        "      FP[3] +=1\n",
        "    elif Y_pred[i] != 1 and Y_true[i] == 1:\n",
        "      FN[0] +=1\n",
        "    elif Y_pred[i] != 4 and Y_true[i] == 4:\n",
        "      FN[1] +=1\n",
        "    elif Y_pred[i] != 7 and Y_true[i] == 7:\n",
        "      FN[2] +=1\n",
        "    elif Y_pred[i] != 9 and Y_true[i] == 9:\n",
        "      FN[3] +=1\n",
        "  \n",
        "  precision[0] = 1.0*np.sum(TP) /(np.sum(TP) +  np.sum(FP))\n",
        "  recall[0]    = 1.0*np.sum(TP) /(np.sum(TP) +  np.sum(FN))\n",
        "  f1_score[0]  = 2.0*precision[0]*recall[0]/(recall[0]+precision[0])\n",
        "  for i in range(0, 4):\n",
        "    precision[i+1] = 1.0*TP[i] / (TP[i] + FP[i])\n",
        "    recall[i+1]    = 1.0*TP[i] / (TP[i] + FN[i])\n",
        "    f1_score[i+1]  = 2.0*precision[i+1]*recall[i+1]/(recall[i+1]+precision[i+1])\n",
        "\n",
        "  ## END TODO\n",
        "\n",
        "  assert len(precision)==5 and len(recall)==5 and len(f1_score)==5\n",
        "\n",
        "  return (precision, recall, f1_score)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyVYAPhtm_At"
      },
      "source": [
        "X_train, Y_train, X_val, Y_val = split_data(X,Y)\n",
        "param_lists, loss_list = train_multi_class(X_train, Y_train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q82oEeRF-guz"
      },
      "source": [
        "def plot_training_loss(loss_list):\n",
        "  labels = [\"1\", \"4\", \"7\", \"9\"]\n",
        "  for ids, loss in enumerate(loss_list):\n",
        "    plt.plot(loss, label = labels[ids])\n",
        "  plt.legend(loc='best')\n",
        "  plt.title('Training Loss of each class (1 vs all)')\n",
        "  plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kL6ByDgZyI"
      },
      "source": [
        "## Plot curve for loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC3lGdUy-jek",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c9e4afae-a49a-460b-ea92-17f2038a7b64"
      },
      "source": [
        "plot_training_loss(loss_list)\n",
        "# print(loss_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNTZuQF8nDTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e73d69e-8267-4859-d3a9-401607ff3828"
      },
      "source": [
        "Y_pred = to_class( prediction(param_lists, X_val) )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVkva3PIgcsu"
      },
      "source": [
        "## Calculate accuracy, precision , recall and F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slH97B8L0iHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108a914c-ea93-4ce3-81a0-7c5206a17ed8"
      },
      "source": [
        "accuracy(Y_pred, Y_val)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuray :  0.925\n",
            "Accuray class 1 :  1.0\n",
            "Accuray class 4 :  0.9468085106382979\n",
            "Accuray class 7 :  0.9074074074074074\n",
            "Accuray class 9 :  0.845360824742268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.925, 1.0, 0.9468085106382979, 0.9074074074074074, 0.845360824742268]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLSImjxiweiV"
      },
      "source": [
        "precision, recall, f1_score = calculate_metrics(Y_pred, Y_val)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wAeIpChvn20",
        "outputId": "acdc0f18-1978-4e21-dab3-5122446ad8a6"
      },
      "source": [
        "# print(\"precision\", precision)\n",
        "# print(\"recall\", recall)\n",
        "# print(\"f1_score\", f1_score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision [0.925, 0.9351851851851852, 0.9175257731958762, 0.9423076923076923, 0.9010989010989011]\n",
            "recall [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "f1_score [0.961038961038961, 0.9665071770334929, 0.956989247311828, 0.9702970297029703, 0.9479768786127168]\n"
          ]
        }
      ]
    }
  ]
}